import google.generativeai as genai
import cv2
import base64
from PIL import Image
import io
import re
import numpy as np # For np.linspace
from core.config import Config
from core.logger import logger

class VLMAnalyzer:
    def __init__(self, config: Config):
        self.config = config
        genai.configure(api_key=self.config.GEMINI_API_KEY)
        self.model = genai.GenerativeModel(self.config.VLM_MODEL_NAME)
        logger.success(f"VLM model '{self.config.VLM_MODEL_NAME}' initialized for analysis.")

    def analyze_and_explain(self, frame_sequence: list, constraints: str) -> dict:
        """
        Analyzes a sequence of frames (as a list of PIL Image objects) against given constraints using VLM.
        Args:
            frame_sequence (list): A list of PIL Image objects for the video segment.
            constraints (str): Natural language constraints generated by the LLM.
        Returns:
            dict: Decision (cheating/not cheating) and explanation.
        """
        if not frame_sequence:
            return {"decision": "No Visual Data", "explanation": "No frames provided for analysis."}

        # Prepare content for VLM - Google Gemini's vision models accept up to 16 images
        # Select evenly spaced frames if the sequence is too long
        max_images_for_gemini = 16
        if len(frame_sequence) > max_images_for_gemini:
            indices = np.linspace(0, len(frame_sequence) - 1, max_images_for_gemini, dtype=int)
            selected_frames = [frame_sequence[i] for i in indices]
        else:
            selected_frames = frame_sequence

        image_parts = []
        for img in selected_frames:
            # Ensure img is a PIL Image
            if not isinstance(img, Image.Image):
                logger.warning("Warning: Expected PIL Image, got different type. Attempting conversion.")
                if isinstance(img, np.ndarray):
                    img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
                else:
                    logger.error(f"Error: Cannot convert image type {type(img)}")
                    continue # Skip this frame

            buffered = io.BytesIO()
            img.save(buffered, format="JPEG", quality=80) # Use JPEG with quality for smaller size
            image_parts.append({
                'mime_type': 'image/jpeg',
                'data': base64.b64encode(buffered.getvalue()).decode('utf-8')
            })

        if not image_parts:
            return {"decision": "No Valid Images", "explanation": "Could not prepare valid images for VLM analysis."}

        prompt_parts = [
            f"Analyze the following sequence of images from an exam. The original alert suggested a suspicious event. Based on these visual frames, and strictly adhering to the following verification constraints, determine if cheating is confirmed and provide a detailed explanation:\n\nConstraints: {constraints}\n\n"
            f"Please format your response strictly as:\nDecision: [Cheating Confirmed / Not Cheating / Ambiguous]\nExplanation: [Detailed explanation of reasoning based on visual evidence and constraints from the image sequence.]\n\n",
            *image_parts, # Unpack image parts here
        ]

        try:
            response = self.model.generate_content(prompt_parts)
            # Access the first part of the first candidate's content
            if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                response_text = response.candidates[0].content.parts[0].text

                # Use regex to parse decision and explanation reliably
                decision_match = re.search(r"Decision:\s*(.+?)(?:\n|$)", response_text, re.IGNORECASE)
                explanation_match = re.search(r"Explanation:\s*(.+)", response_text, re.IGNORECASE | re.DOTALL)

                decision = decision_match.group(1).strip() if decision_match else "Unclear"
                explanation = explanation_match.group(1).strip() if explanation_match else response_text

                return {"decision": decision, "explanation": explanation}
            else:
                # Handle cases where response might be empty or blocked due to safety settings
                safety_ratings = response.prompt_feedback.safety_ratings if response.prompt_feedback else "N/A"
                logger.warning(f"VLM response did not contain expected content or was blocked. Safety Ratings: {safety_ratings}")
                return {"decision": "Error", "explanation": f"VLM could not process the request or response was empty/blocked. Safety: {safety_ratings}"}
        except Exception as e:
            logger.error(f"Error calling VLM for analysis: {e}")
            return {"decision": "Error", "explanation": f"VLM API error: {e}. Check API key, quota, or input content."}


